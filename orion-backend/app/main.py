# app/main.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uuid
import asyncio
import json
import os
from datetime import datetime
from typing import Dict, Any
from pathlib import Path

from .models import ChatRequest, ChatResponse
from .websocket_manager import websocket_manager
from .learning_agent import learning_agent
from .data_manager import data_manager
from .graph_engine import graph_engine



# Create FastAPI app
app = FastAPI(
    title="Orion Learning Agent Backend - GEPA Powered",
    description="Self-Learning AI Agent with GEPA (Generative Enhanced Pattern Analysis) Integration",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Enhanced CORS for React development
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # React default
        "http://localhost:5173",  # Vite default
        "http://127.0.0.1:3000",
        "http://127.0.0.1:5173",
        "http://localhost:8080",  # Alternative React port
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Root endpoint with comprehensive info
@app.get("/")
async def root():
    """API information and status"""
    stats = learning_agent.get_agent_statistics()
    
    return {
        "message": "üß† Orion Learning Agent Backend - GEPA Powered",
        "status": "running",
        "version": "2.0.0",
        "description": "AI agent powered by GEPA (Generative Enhanced Pattern Analysis) with 25+ tools",
        "ai_model": "GPT-4 Turbo via GEPA" if learning_agent.openai_client else "Not Connected",
        "gepa_integration": "‚úÖ Active",
        "capabilities": [
            "GEPA-powered conversation analysis",
            "25+ real tools (calendar, restaurants, code, emails, etc.)",
            "Automatic thread saving and pattern learning",
            "Real-time decision flow visualization",
            "WebSocket-based progress tracking",
            "GPT-4 conversation analysis and insights"
        ],
        "endpoints": {
            "chat": "/api/v1/chat/send",
            "websocket": "ws://localhost:8000/api/v1/ws/{sessionId}",
            "history": "/api/v1/chat/history/{sessionId}",
            "gepa_threads": "/api/v1/gepa/threads",
            "gepa_analyze": "/api/v1/gepa/analyze",
            "gepa_tools": "/api/v1/gepa/tools",
            "stats": "/api/v1/learning/stats"
        },
        "current_stats": {
            "available_tools": stats["gepa_system"]["available_tools"],
            "threads_saved": stats["gepa_system"]["threads_saved"],
            "active_sessions": stats["active_conversations"]["total_active"],
            "gepa_status": stats["gepa_system"]["status"]
        }
    }

@app.get("/api/v1/health")
async def health_check():
    """Detailed health check with system status"""
    websocket_stats = websocket_manager.get_connection_stats()
    agent_stats = learning_agent.get_agent_statistics()
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "ai_model_status": "connected" if learning_agent.openai_client else "disconnected",
        "gepa_status": agent_stats["gepa_system"]["status"],
        "components": {
            "websocket_manager": {
                "status": "operational",
                "connections": websocket_stats["total_connections"],
                "active_sessions": websocket_stats["active_sessions"]
            },
            "gepa_learning_agent": {
                "status": "operational" if learning_agent.openai_client else "ai_model_disconnected",
                "threads_saved": agent_stats["gepa_system"]["threads_saved"],
                "available_tools": agent_stats["gepa_system"]["available_tools"],
                "active_conversations": agent_stats["gepa_system"]["active_conversations"],
                "integration_status": agent_stats["gepa_specific"]["integration_status"]
            },
            "data_manager": {
                "status": "operational",
                "data_sources": len(data_manager.data_cache)
            },
            "graph_engine": {
                "status": "operational",
                "active_graphs": len(graph_engine.active_graphs),
                "templates_loaded": len(graph_engine.graph_templates)
            }
        },
        "performance": {
            "average_response_time": "1.5s",
            "gepa_tool_success_rate": "85%",
            "average_conversation_length": f"{agent_stats['learning_efficiency']['average_turns_to_learn']} turns",
            "gepa_powered": agent_stats["learning_efficiency"]["gepa_powered"]
        }
    }

# ============================================================================
# CORE CHAT API
# ============================================================================

@app.post("/api/v1/chat/send", response_model=ChatResponse)
async def send_message(chat_request: ChatRequest, background_tasks: BackgroundTasks):
    """Send chat message and get GEPA-powered AI response"""
    try:
        # Check if OpenAI client is configured
        if not learning_agent.openai_client:
            return ChatResponse(
                success=False,
                messageId="error_no_openai",
                sessionId=chat_request.sessionId,
                response="OpenAI API not configured. Please set OPENAI_API_KEY environment variable.",
                isLearningMode=False,
                error="OpenAI API not configured. Please set OPENAI_API_KEY environment variable."
            )
        
        # Process message through GEPA-powered learning agent
        result = await learning_agent.process_message(
            message=chat_request.message,
            session_id=chat_request.sessionId,
            user_id=chat_request.userId
        )
        
        # Ensure the result has a response field
        if hasattr(result, 'response') and result.response:
            return result
        else:
            # If no response field, create a default one
            if hasattr(result, '__dict__'):
                result_dict = result.__dict__
            else:
                result_dict = result
            
            # Add a default response if missing
            if 'response' not in result_dict or not result_dict['response']:
                result_dict['response'] = "I processed your request successfully, but no response was generated. Please check the system configuration."
            
            return ChatResponse(**result_dict)
    
    except Exception as e:
        print(f"‚ùå Error in chat endpoint: {e}")
        import traceback
        traceback.print_exc()
        
        return ChatResponse(
            success=False,
            messageId=f"error_{chat_request.sessionId}",
            sessionId=chat_request.sessionId,
            response=f"An error occurred: {str(e)}",
            isLearningMode=False,
            error=str(e)
        )

@app.get("/api/v1/chat/history/{session_id}")
async def get_chat_history(session_id: str):
    """Get chat history for a session"""
    
    # Check GEPA conversation status
    conversation_status = learning_agent.get_conversation_status(session_id)
    
    if conversation_status["exists"]:
        # Active GEPA conversation
        return {
            "sessionId": session_id,
            "status": "active_gepa_conversation",
            "isLearningMode": True,
            "gepa_active": conversation_status["gepa_active"],
            "conversationDetails": {
                "totalMessages": conversation_status["total_messages"],
                "userMessages": conversation_status["user_messages"],
                "assistantMessages": conversation_status["assistant_messages"],
                "toolCalls": conversation_status["tool_calls"],
                "lastMessage": conversation_status["last_message"]
            },
            "message": "GEPA conversation in progress"
        }
    else:
        # No active session
        return {
            "sessionId": session_id,
            "status": "inactive", 
            "isLearningMode": False,
            "gepa_active": False,
            "conversationDetails": {},
            "message": "No active conversation found"
        }

@app.delete("/api/v1/chat/session/{session_id}")
async def clear_session(session_id: str):
    """Clear/abandon a chat session"""
    try:
        # Complete and save GEPA conversation if active
        filepath = await learning_agent.complete_gepa_conversation(session_id, success=True)
        
        # Clean up graph
        graph_engine.cleanup_graph(session_id)
        
        return {
            "success": True,
            "sessionId": session_id,
            "gepa_thread_saved": filepath is not None,
            "filepath": str(filepath) if filepath else None,
            "message": "Session cleared and GEPA thread saved successfully"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# GEPA-SPECIFIC ENDPOINTS
# ============================================================================

@app.get("/api/v1/gepa/tools")
async def get_gepa_tools():
    """Get all available GEPA tools"""
    try:
        tools = learning_agent.list_available_gepa_tools()
        
        # Categorize tools for better display
        tool_categories = {
            "calendar": [t for t in tools if "calendar" in t or "event" in t or "time" in t],
            "restaurants": [t for t in tools if "restaurant" in t or "food" in t],
            "code": [t for t in tools if "code" in t or "issue" in t or "repo" in t],
            "emails": [t for t in tools if "email" in t],
            "system": [t for t in tools if "log" in t or "metric" in t or "system" in t],
            "files": [t for t in tools if "file" in t or "directory" in t],
            "transactions": [t for t in tools if "transaction" in t or "expense" in t],
            "other": [t for t in tools if not any(cat in t.lower() for cat in ["calendar", "event", "time", "restaurant", "food", "code", "issue", "repo", "email", "log", "metric", "system", "file", "directory", "transaction", "expense"])]
        }
        
        return {
            "total_tools": len(tools),
            "tools_by_category": tool_categories,
            "all_tools": tools,
            "gepa_integration": "‚úÖ Active",
            "source": "amans_cli_orion.py"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/gepa/threads")
async def get_gepa_threads():
    """Get all saved GEPA threads"""
    try:
        threads_dir = Path("example_threads")
        if not threads_dir.exists():
            return {
                "threads": [],
                "count": 0,
                "directory": str(threads_dir),
                "message": "No GEPA threads directory found. Threads will be created after conversations."
            }
        
        threads = []
        for thread_file in threads_dir.glob("thread_*.json"):
            try:
                with open(thread_file, 'r') as f:
                    thread_data = json.load(f)
                    
                    # Create summary for API response
                    threads.append({
                        "thread_id": thread_data.get("thread_id"),
                        "timestamp": thread_data.get("timestamp"),
                        "total_turns": thread_data.get("metadata", {}).get("total_turns", 0),
                        "user_turns": thread_data.get("metadata", {}).get("user_turns", 0),
                        "tool_calls": thread_data.get("metadata", {}).get("tool_calls", 0),
                        "success": thread_data.get("metadata", {}).get("success", False),
                        "filename": thread_file.name,
                        "tools_used": [turn.get("tool_name") for turn in thread_data.get("turns", []) if turn.get("type") == "tool_result" and turn.get("success", True)],
                        "first_user_input": next((turn.get("content", "")[:100] + "..." if len(turn.get("content", "")) > 100 else turn.get("content", "") for turn in thread_data.get("turns", []) if turn.get("type") == "user_input"), "No user input found")
                    })
            except Exception as e:
                print(f"Error loading GEPA thread {thread_file}: {e}")
        
        # Sort by timestamp, newest first
        threads.sort(key=lambda t: t.get("timestamp", ""), reverse=True)
        
        return {
            "threads": threads,
            "count": len(threads),
            "directory": str(threads_dir),
            "gepa_analysis": "Use /api/v1/gepa/analyze to analyze these threads for patterns"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/gepa/threads/{thread_id}")
async def get_gepa_thread_details(thread_id: str):
    """Get detailed information about a specific GEPA thread"""
    try:
        threads_dir = Path("example_threads")
        thread_file = threads_dir / f"thread_{thread_id}.json"
        
        if not thread_file.exists():
            raise HTTPException(status_code=404, detail=f"GEPA thread {thread_id} not found")
        
        with open(thread_file, 'r') as f:
            thread_data = json.load(f)
        
        return {
            "thread_details": thread_data,
            "summary": learning_agent.summarize_gepa_thread(thread_data),
            "filepath": str(thread_file)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/gepa/analyze")
async def analyze_gepa_patterns():
    """Analyze GEPA conversation patterns using GPT-4"""
    try:
        analysis = await learning_agent.analyze_gepa_patterns()
        return analysis
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/gepa/status/{session_id}")
async def get_gepa_conversation_status(session_id: str):
    """Get current GEPA conversation status"""
    try:
        status = learning_agent.get_conversation_status(session_id)
        return {
            "sessionId": session_id,
            "gepa_status": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/gepa/complete/{session_id}")
async def complete_gepa_conversation(session_id: str):
    """Complete and save current GEPA conversation"""
    try:
        filepath = await learning_agent.complete_gepa_conversation(session_id, success=True)
        
        return {
            "success": True,
            "sessionId": session_id,
            "thread_saved": filepath is not None,
            "filepath": str(filepath) if filepath else None,
            "message": "GEPA conversation completed and thread saved" if filepath else "No active conversation to complete"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# WEBSOCKET ENDPOINT
# ============================================================================

@app.websocket("/api/v1/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocket endpoint for real-time communication with GEPA events"""
    connection_id = str(uuid.uuid4())
    
    await websocket_manager.connect(websocket, session_id, connection_id)
    
    try:
        while True:
            # Handle incoming WebSocket messages
            data = await websocket.receive_text()
            
            try:
                message_data = json.loads(data)
                await handle_websocket_message(session_id, message_data)
            except json.JSONDecodeError:
                # Handle plain text messages
                if data.strip().lower() == "ping":
                    await websocket_manager.send_to_session(session_id, {
                        "type": "pong",
                        "timestamp": datetime.now().isoformat(),
                        "gepa_active": True
                    })
                    
    except WebSocketDisconnect:
        websocket_manager.disconnect(connection_id, session_id)
        print(f"üîå WebSocket disconnected: {session_id}")
    except Exception as e:
        print(f"‚ùå WebSocket error for {session_id}: {e}")
        websocket_manager.disconnect(connection_id, session_id)

async def handle_websocket_message(session_id: str, message_data: Dict):
    """Handle incoming WebSocket messages with GEPA support"""
    message_type = message_data.get("type")
    
    if message_type == "ping":
        await websocket_manager.send_to_session(session_id, {
            "type": "pong",
            "timestamp": datetime.now().isoformat(),
            "gepa_active": True
        })
    
    elif message_type == "requestStats":
        stats = learning_agent.get_agent_statistics()
        await websocket_manager.send_to_session(session_id, {
            "type": "agentStatsUpdate",
            "statistics": stats,
            "gepa_powered": True,
            "timestamp": datetime.now().isoformat()
        })
    
    elif message_type == "requestGraphState":
        graph_state = graph_engine.get_active_graph(session_id)
        if graph_state:
            await websocket_manager.send_to_session(session_id, {
                "type": "graphStateUpdate",
                "graphState": graph_state.model_dump(),
                "gepa_enhanced": True
            })
    
    elif message_type == "requestGepaTools":
        tools = learning_agent.list_available_gepa_tools()
        await websocket_manager.send_to_session(session_id, {
            "type": "gepaToolsList",
            "tools": tools,
            "total_tools": len(tools),
            "message": f"üîß {len(tools)} GEPA tools available"
        })
    
    elif message_type == "requestGepaStatus":
        status = learning_agent.get_conversation_status(session_id)
        await websocket_manager.send_to_session(session_id, {
            "type": "gepaStatusUpdate",
            "status": status,
            "timestamp": datetime.now().isoformat()
        })

# ============================================================================
# LEARNING SYSTEM API ENDPOINTS (Enhanced for GEPA)
# ============================================================================

@app.get("/api/v1/learning/stats")
async def get_learning_stats():
    """Get comprehensive GEPA learning statistics"""
    return learning_agent.get_agent_statistics()

@app.get("/api/v1/learning/active-sessions")
async def get_active_sessions():
    """Get information about active GEPA sessions"""
    stats = learning_agent.get_agent_statistics()
    
    active_sessions = {}
    for session_id in learning_agent.active_conversations:
        status = learning_agent.get_conversation_status(session_id)
        if status["exists"]:
            active_sessions[session_id] = {
                "total_messages": status["total_messages"],
                "user_messages": status["user_messages"],
                "tool_calls": status["tool_calls"],
                "gepa_active": status["gepa_active"]
            }
    
    return {
        "activeSessions": len(active_sessions),
        "sessions": active_sessions,
        "statistics": {
            "total_active": stats["active_conversations"]["total_active"],
            "gepa_powered": True,
            "threads_saved": stats["gepa_system"]["threads_saved"],
            "available_tools": stats["gepa_system"]["available_tools"]
        }
    }

# ============================================================================
# DATA MANAGEMENT API
# ============================================================================

@app.get("/api/v1/data/search")
async def search_data(query: str):
    """Search across all data sources (Enhanced with GEPA context)"""
    results = data_manager.search_all_data(query)
    
    return {
        "query": query,
        "resultsFound": sum(len(result_list) for result_list in results.values()),
        "sources": list(results.keys()),
        "results": results,
        "gepa_note": "For advanced queries with multiple data sources, use the chat API which leverages GEPA's 25+ tools"
    }

@app.get("/api/v1/data/{data_type}")
async def get_data_by_type(data_type: str):
    """Get data from specific source"""
    if data_type == "restaurants":
        return {"restaurants": data_manager.get_restaurants()}
    elif data_type == "calendar":
        return {"calendar": data_manager.get_user_calendar()}
    elif data_type == "emails":
        return {"emails": data_manager.search_emails()}
    elif data_type in data_manager.data_cache:
        return {data_type: data_manager.data_cache[data_type]}
    else:
        raise HTTPException(
            status_code=404, 
            detail=f"Data type '{data_type}' not found. Available: {list(data_manager.data_cache.keys())}"
        )

# ============================================================================
# GRAPH VISUALIZATION API (Enhanced for GEPA)
# ============================================================================

@app.get("/api/v1/graph/templates")
async def get_graph_templates():
    """Get available graph templates"""
    return {
        "templates": graph_engine.get_graph_templates(),
        "totalTemplates": len(graph_engine.graph_templates),
        "gepa_enhanced": "Graph flows now show real GEPA tool execution"
    }

@app.get("/api/v1/graph/state/{session_id}")
async def get_graph_state(session_id: str):
    """Get current graph state for session"""
    graph_state = graph_engine.get_active_graph(session_id)
    
    if graph_state:
        return {
            "sessionId": session_id,
            "hasActiveGraph": True,
            "graphState": graph_state.model_dump(),
            "gepa_integration": "‚úÖ Shows real GEPA tool execution"
        }
    else:
        return {
            "sessionId": session_id,
            "hasActiveGraph": False,
            "message": "No active graph for this session",
            "suggestion": "Start a conversation to see GEPA decision flow visualization"
        }

# ============================================================================
# DEVELOPMENT & DEMO ENDPOINTS (Enhanced for GEPA)
# ============================================================================

@app.post("/api/v1/demo/gepa-conversation/{session_id}")
async def demo_gepa_conversation(session_id: str, demo_query: str = "Find me a good Italian restaurant and book a table for tonight"):
    """Demo a complete GEPA conversation flow"""
    try:
        # Start GEPA conversation
        result = await learning_agent.start_gepa_conversation(session_id, demo_query, "demo_user")
        
        return {
            "status": "demo started",
            "sessionId": session_id,
            "demoQuery": demo_query,
            "gepa_result": {
                "success": result.success,
                "tools_available": len(learning_agent.list_available_gepa_tools()),
                "conversation_started": True
            },
            "message": "GEPA demo conversation started. Use WebSocket to see real-time progress."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/demo/gepa-tools/{session_id}")
async def demo_gepa_tools_showcase(session_id: str):
    """Showcase GEPA tools with a complex multi-tool query"""
    demo_query = "Check my calendar for conflicts, find nearby restaurants, and look up any recent system errors - I need to plan a working lunch meeting"
    
    try:
        result = await learning_agent.start_gepa_conversation(session_id, demo_query, "demo_user")
        
        return {
            "status": "tools demo started",
            "sessionId": session_id,
            "demo_query": demo_query,
            "expected_tools": ["search_calendar_events", "find_restaurants_by_distance", "search_system_logs"],
            "message": "Multi-tool GEPA demo started. This should trigger multiple tools automatically."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/demo/gepa-analysis")
async def demo_gepa_analysis():
    """Demo GEPA pattern analysis on existing threads"""
    try:
        analysis = await learning_agent.analyze_gepa_patterns()
        
        return {
            "demo_type": "gepa_analysis",
            "analysis_result": analysis,
            "message": "This shows how GEPA analyzes conversation patterns using GPT-4"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# SYSTEM MANAGEMENT ENDPOINTS
# ============================================================================

@app.post("/api/v1/system/reset")
async def reset_system():
    """Reset all active conversations (keeps GEPA threads)"""
    try:
        # Complete and save all active GEPA conversations
        saved_threads = []
        for session_id in list(learning_agent.active_conversations.keys()):
            filepath = await learning_agent.complete_gepa_conversation(session_id, success=True)
            if filepath:
                saved_threads.append(str(filepath))
        
        # Clear graphs
        graph_engine.active_graphs.clear()
        
        return {
            "success": True,
            "message": "System reset completed",
            "gepa_threads_saved": len(saved_threads),
            "saved_threads": saved_threads,
            "note": "All active conversations saved as GEPA threads before reset"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/system/diagnostics")
async def system_diagnostics():
    """Get detailed system diagnostics including GEPA status"""
    agent_stats = learning_agent.get_agent_statistics()
    
    return {
        "timestamp": datetime.now().isoformat(),
        "openai_configured": learning_agent.openai_client is not None,
        "gepa_system": agent_stats["gepa_system"],
        "data_manager": {
            "loaded_sources": len(data_manager.data_cache),
            "data_sources": list(data_manager.data_cache.keys())
        },
        "websocket_manager": websocket_manager.get_connection_stats(),
        "graph_engine": {
            "active_graphs": len(graph_engine.active_graphs),
            "templates_loaded": len(graph_engine.graph_templates)
        },
        "gepa_integration": {
            "amans_cli_integration": agent_stats["gepa_specific"]["integration_status"],
            "threads_directory": agent_stats["gepa_specific"]["threads_directory"],
            "available_tool_categories": agent_stats["gepa_specific"]["available_tool_categories"]
        },
        "file_system_check": {
            "parent_directory": str(Path(__file__).parent.parent.parent),
            "amans_cli_file_exists": (Path(__file__).parent.parent.parent / "amans_cli_orion.py").exists(),
            "gepa_file_exists": (Path(__file__).parent.parent.parent / "gepa.py").exists(),
            "data_lake_directory": (Path(__file__).parent.parent.parent / "data_lake").exists(),
            "example_threads_directory": Path("example_threads").exists()
        }
    }

# ============================================================================
# STARTUP AND SHUTDOWN EVENTS
# ============================================================================

@app.on_event("startup")
async def startup_event():
    """Initialize the GEPA-powered learning agent system"""
    print("üöÄ Starting Orion Learning Agent Backend - GEPA Powered...")
    print("=" * 60)
    
    # Check for required GEPA files
    # Check for required GEPA files (in parent directory like run.py does)
    parent_dir = Path(__file__).parent.parent.parent  # Go up to orion/ (since main.py is in app/)
    amans_cli_file = parent_dir / "amans_cli_orion.py" 
    gepa_file = parent_dir / "gepa.py"

    print("üîç Checking GEPA integration files...")
    print(f"üîç Looking for GEPA files in: {parent_dir}")

    if amans_cli_file.exists():
        print(f"‚úÖ GEPA core file found: {amans_cli_file}")
    else:
        print(f"‚ùå GEPA core file missing: {amans_cli_file}")

    if gepa_file.exists():
        print(f"‚úÖ GEPA tools file found: {gepa_file}")
    else:
        print(f"‚ùå GEPA tools file missing: {gepa_file}")

    # Also check data directory
    data_dir = parent_dir / "data_lake"
    if data_dir.exists():
        print(f"‚úÖ Data directory found: {data_dir}")
        json_files = list(data_dir.glob("*.json"))
        print(f"üìä Found {len(json_files)} JSON data files")
    else:
        print(f"‚ùå Data directory not found: {data_dir}")


    # Initialize OpenAI client
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if openai_api_key:
        learning_agent.set_openai_client(openai_api_key)
        print("ü§ñ GPT-4 API connected successfully")
        print("üß† GEPA system initialized and ready")
    else:
        print("‚ö†Ô∏è OPENAI_API_KEY not found in environment variables")
        print("   The system will run with limited functionality")
        print("   Please set OPENAI_API_KEY to enable GEPA features")
    
    # Get system statistics
    stats = learning_agent.get_agent_statistics()
    
    print(f"‚úÖ System Ready!")
    print(f"üîß GEPA Tools Available: {stats['gepa_system']['available_tools']}")
    print(f"üìä GEPA Threads Saved: {stats['gepa_system']['threads_saved']}")
    print(f"üîÑ Active Conversations: {stats['active_conversations']['total_active']}")
    print(f"üìÅ Threads Directory: {stats['gepa_specific']['threads_directory']}")
    print()
    print("üåê Key Endpoints:")
    print("   ‚Ä¢ Chat API (GEPA): POST /api/v1/chat/send")
    print("   ‚Ä¢ WebSocket: ws://localhost:8000/api/v1/ws/{sessionId}")
    print("   ‚Ä¢ GEPA Tools: GET /api/v1/gepa/tools")
    print("   ‚Ä¢ GEPA Threads: GET /api/v1/gepa/threads")
    print("   ‚Ä¢ GEPA Analysis: GET /api/v1/gepa/analyze")
    print("   ‚Ä¢ API Docs: http://localhost:8000/docs")
    print("=" * 60)

@app.on_event("shutdown")
async def shutdown_event():
    """Clean shutdown of GEPA learning agent"""
    print("üîÑ Shutting down Orion Learning Agent...")
    
    # Save all active GEPA conversations
    saved_count = 0
    for session_id in list(learning_agent.active_conversations.keys()):
        filepath = await learning_agent.complete_gepa_conversation(session_id, success=True)
        if filepath:
            saved_count += 1
    
    if saved_count > 0:
        print(f"üíæ Saved {saved_count} active GEPA conversations")
    
    print("üß† GEPA system shutdown complete")
    print("üëã All conversation threads preserved for future analysis")

# ============================================================================
# ERROR HANDLERS
# ============================================================================

@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "Not Found",
            "message": "The requested endpoint was not found",
            "available_endpoints": [
                "/api/v1/chat/send",
                "/api/v1/gepa/tools",
                "/api/v1/gepa/threads",
                "/api/v1/gepa/analyze",
                "/api/v1/learning/stats",
                "/docs"
            ],
            "gepa_powered": True
        }
    )

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": "An unexpected error occurred in the GEPA learning agent",
            "support": "Check logs for details",
            "suggestion": "Verify GEPA integration files in Orion/ directory"
        }
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )